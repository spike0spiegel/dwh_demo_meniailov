Это мой учебный проект в PostgreSQL. Идея в том, что из источника (csv файлы) данные о продажах в сети магазинов проходят через несколько ступеней и попадают в таблицы в слое 3nf и в слое dm. При изменении csv файла и повторном запуске загрузки в будут загружены только новые данные, а старые, если в них были изменения, редактированы.

Описание файлов с кодом:

@https://github.com/spike0spiegel/dwh_demo_meniailov/blob/main/dataset_creation.ipynb(dataset_creation.ipynb) - это код на Python, который берёт первичный датасет, скаченный с kaggle и приводит его к подходящему к требованиям проекта состоянию. В основном там удаляются ненужные колонки и добавляются новые. Используется pandas, numpy и библиотека Faker для генерации данных.



